{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb4f06f-21f2-4009-b57d-6b935c6d3100",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "8eb4f06f-21f2-4009-b57d-6b935c6d3100",
    "outputId": "2decedfd-1aa4-4b37-df1d-c34d46bde42c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load embeddings\n",
    "embeddings_path = 'yars_data/base_out/features.pt'\n",
    "embeddings = torch.load(embeddings_path)\n",
    "embeddings = embeddings[1:]\n",
    "\n",
    "# Load paths\n",
    "paths_file = 'yars_data/base_out/paths.txt'\n",
    "with open(paths_file, 'r') as file:\n",
    "    paths = file.readlines()\n",
    "paths = paths[1:]\n",
    "\n",
    "base_dir = 'yars_data/photos/'\n",
    "paths = [base_dir + path.strip() for path in paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25199c43-4a12-40db-bf2e-9f641cf54d3e",
   "metadata": {
    "id": "25199c43-4a12-40db-bf2e-9f641cf54d3e"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# photo_directory = 'yars_data/photos/'\n",
    "# paths = [photo_directory + path for path in paths]\n",
    "\n",
    "# Perform PCA to reduce to 300 components\n",
    "pca = PCA(n_components=300)\n",
    "pca_results = pca.fit_transform(embeddings.numpy())\n",
    "\n",
    "n_clusters = 20\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "clusters = kmeans.fit_predict(pca_results)\n",
    "\n",
    "cluster_images = {i: [] for i in range(n_clusters)}\n",
    "cluster_embeddings = {i: [] for i in range(n_clusters)}\n",
    "for i in range(len(clusters)):\n",
    "    cluster = clusters[i]\n",
    "    cluster_images[cluster].append(paths[i])\n",
    "    cluster_embeddings[cluster].append(embeddings[i])\n",
    "\n",
    "# print(cluster_images.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a95a1-4db7-4996-9c0f-fd834c28ff77",
   "metadata": {
    "id": "a37a95a1-4db7-4996-9c0f-fd834c28ff77"
   },
   "outputs": [],
   "source": [
    "k = 25\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='euclidean')\n",
    "\n",
    "test_embeddings_path = 'test/caption_features.pt'\n",
    "test_embeddings = torch.load(test_embeddings_path)\n",
    "test_embeddings = test_embeddings\n",
    "\n",
    "test_paths_path = 'test/caption_paths.txt'\n",
    "with open(test_paths_path, 'r') as file:\n",
    "    test_paths = file.readlines()\n",
    "test_paths = test_paths\n",
    "\n",
    "new_points_pca = pca.transform(test_embeddings.detach().numpy())\n",
    "new_labels = kmeans.predict(new_points_pca)\n",
    "print(len(test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f863a1-3a66-48c2-a073-ba03f4628f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'yars_data'\n",
    "\n",
    "photos_data = {}\n",
    "with open(os.path.join(root_dir, 'photos.json'), 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.rstrip()\n",
    "            try:\n",
    "                photo_record = json.loads(line)\n",
    "                photos_data[photo_record['photo_id']] = photo_record\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e} at line: {line}\")\n",
    "\n",
    "test_results = []\n",
    "for i, label in enumerate(new_labels):\n",
    "    test_cluster = cluster_embeddings[label]\n",
    "    image_cluster = cluster_images[label]\n",
    "    nbrs.fit(test_cluster)\n",
    "    distances, indices = nbrs.kneighbors([test_embeddings[0]])\n",
    "    \n",
    "    print(f\"Neighbors found for test image {i}\")\n",
    "    neighbor_captions = []\n",
    "    \n",
    "    for idx in indices[0]:\n",
    "        image_id = image_cluster[idx].split('/')[-1][:-4]\n",
    "        neighbor_captions.append(photos_data[image_id][\"caption\"])\n",
    "\n",
    "    test_results.append(neighbor_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f02bf1-b90c-4971-8040-8f9edcb38060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_and_count(captions):\n",
    "    # Regular expression to find words\n",
    "    word_pattern = re.compile(r'\\b\\w+\\b')\n",
    "    text = ' '.join(captions).lower()\n",
    "    words = word_pattern.findall(text)\n",
    "    frequency = Counter(words)\n",
    "    return frequency\n",
    "\n",
    "test_display_count = 5\n",
    "k = 5 # top-k labels\n",
    "fig, axs = plt.subplots(5, 1, figsize=(10, 15))\n",
    "\n",
    "for i, neighbor_captions in enumerate(test_results[:test_display_count]):\n",
    "    im = Image.open(test_paths[i])\n",
    "    freq = tokenize_and_count(neighbor_captions)\n",
    "    filtered_counts = {word: count for word, count in freq.items() if word not in stop_words}\n",
    "    \n",
    "    axs[i, 0].imshow(im)\n",
    "    axs[i, j].set_title(f'top-{k} labels using KNN: {\",\".join(sorted(filtered_counts.items(), key=lambda x: x[1], reverse=True)[:k])}')\n",
    "    axs[i, j].axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
